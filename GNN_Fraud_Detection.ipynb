{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uX1xUGNDAdi",
        "outputId": "0c55fbd3-503b-423a-d92d-2939b6862021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "from itertools import combinations\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "from google.colab import drive\n",
        "from scipy.sparse import coo_matrix\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.datasets import WikiCS\n",
        "from torch_geometric.nn import aggr\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def foo(a,ind,sz):\n",
        "    idxs=torch.arange(sz)+ind\n",
        "    return torch.index_select(a,0,idxs)\n",
        "\n",
        "a=torch.arange(20).reshape((2,10))\n",
        "c=torch.tensor([2,5])\n",
        "print(torch.vmap(foo,in_dims=(0,0,None))(a,c,2)) # this is inside a vmap\n",
        "print([foo(suba,subc,2) for (suba,subc) in zip(a,c)]) # but this is the same content"
      ],
      "metadata": {
        "id": "21F5ankHV74A",
        "outputId": "7acb4fab-cf43-4edf-a600-03146f4ce4df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2,  3],\n",
            "        [15, 16]])\n",
            "[tensor([2, 3]), tensor([15, 16])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytzxyXtYDA98"
      },
      "outputs": [],
      "source": [
        "dataset = WikiCS(root='path/to/dataset')\n",
        "\n",
        "# Access the data\n",
        "data = dataset[0]  # Access the first graph in the dataset\n",
        "x = data.x  # Node features\n",
        "edge_index = data.edge_index  # Edges\n",
        "y = data.y  # Node labels\n",
        "train_mask = data.train_mask  # Training mask\n",
        "val_mask = data.val_mask  # Validation mask\n",
        "test_mask = data.test_mask  # Test mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcI1EdcQWYlL"
      },
      "outputs": [],
      "source": [
        "def get_train_split_from_bool(data) :\n",
        "  data = data\n",
        "  adjacency_list = [(i.item(), j.item()) for i, j in zip(data.edge_index[0], data.edge_index[1])]\n",
        "  train_indices = data.train_mask[:, 0]  # assuming we're using the first training split\n",
        "  train_indices = torch.where(train_indices)[0]\n",
        "\n",
        "  X_train = data.x[train_indices]\n",
        "  y_train = data.y[train_indices]\n",
        "\n",
        "  # Create adjacency list for training set\n",
        "  train_nodes = set(train_indices.tolist())\n",
        "  adjacency_list_train = [(i, j) for i, j in adjacency_list if i in train_nodes and j in train_nodes]\n",
        "  edge_index_train = torch.tensor(adjacency_list_train, dtype=torch.long).t().contiguous()\n",
        "\n",
        "  return adjacency_list_train, edge_index_train,X_train,y_train\n",
        "\n",
        "adjacency_list_train, edge_index_train,X_train,y_train = get_train_split_from_bool(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F2Inw6qWYop"
      },
      "outputs": [],
      "source": [
        "def tensor_to_one_hot(labels, num_classes=None):\n",
        "    # Determine the number of classes if not provided\n",
        "    if num_classes is None:\n",
        "        num_classes = labels.max().item() + 1\n",
        "    # Convert labels to one-hot\n",
        "    one_hot_labels = F.one_hot(labels, num_classes=num_classes)\n",
        "\n",
        "    return one_hot_labels.float()\n",
        "\n",
        "num_classes = 10\n",
        "one_hot_labels = tensor_to_one_hot(y, num_classes)\n",
        "one_hot_labels_train = tensor_to_one_hot(y_train, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MnUIPIeUE8f",
        "outputId": "3bea3a29-1d78-4357-a711-e4836eb49192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.3095\n",
            "Epoch 10, Loss: 1.8067\n",
            "Epoch 20, Loss: 1.5905\n",
            "Epoch 30, Loss: 1.4849\n",
            "Epoch 40, Loss: 1.4209\n",
            "Epoch 50, Loss: 1.3820\n",
            "Epoch 60, Loss: 1.3562\n",
            "Epoch 70, Loss: 1.3375\n",
            "Epoch 80, Loss: 1.3236\n",
            "Epoch 90, Loss: 1.3130\n",
            "Epoch 100, Loss: 1.3045\n",
            "Epoch 110, Loss: 1.2977\n",
            "Epoch 120, Loss: 1.2919\n",
            "Epoch 130, Loss: 1.2871\n",
            "Epoch 140, Loss: 1.2830\n",
            "Epoch 150, Loss: 1.2795\n",
            "Epoch 160, Loss: 1.2764\n",
            "Epoch 170, Loss: 1.2737\n",
            "Epoch 180, Loss: 1.2714\n",
            "Epoch 190, Loss: 1.2694\n",
            "Epoch 200, Loss: 1.2676\n",
            "Epoch 210, Loss: 1.2661\n",
            "Epoch 220, Loss: 1.2647\n",
            "Epoch 230, Loss: 1.2634\n",
            "Epoch 240, Loss: 1.2624\n",
            "Epoch 250, Loss: 1.2614\n",
            "Epoch 260, Loss: 1.2605\n",
            "Epoch 270, Loss: 1.2597\n",
            "Epoch 280, Loss: 1.2590\n",
            "Epoch 290, Loss: 1.2584\n",
            "Epoch 300, Loss: 1.2578\n",
            "Epoch 310, Loss: 1.2573\n",
            "Epoch 320, Loss: 1.2568\n",
            "Epoch 330, Loss: 1.2564\n",
            "Epoch 340, Loss: 1.2560\n",
            "Epoch 350, Loss: 1.2557\n",
            "Epoch 360, Loss: 1.2553\n",
            "Epoch 370, Loss: 1.2550\n",
            "Epoch 380, Loss: 1.2548\n",
            "Epoch 390, Loss: 1.2545\n",
            "Epoch 400, Loss: 1.2543\n",
            "Epoch 410, Loss: 1.2541\n",
            "Epoch 420, Loss: 1.2539\n",
            "Epoch 430, Loss: 1.2537\n",
            "Epoch 440, Loss: 1.2536\n",
            "Epoch 450, Loss: 1.2534\n",
            "Epoch 460, Loss: 1.2533\n",
            "Epoch 470, Loss: 1.2531\n",
            "Epoch 480, Loss: 1.2530\n",
            "Epoch 490, Loss: 1.2529\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(300,10),\n",
        "    nn.Tanh()\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# criterion = nn.MSELoss()\n",
        "train_negtest = torch.logical_not(data.test_mask)\n",
        "num_epoch = 500\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  out = model(data.x)\n",
        "  # loss = criterion(out, one_hot_labels)\n",
        "  #train loss\n",
        "  loss = criterion(out, one_hot_labels)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch {epoch}, Loss: {loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kTiV6H2-Y2pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cw6yK0sTY24g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "0) Construct concatenate features matrix ---> concatenated_features_matrix\n",
        "1) Calculate MLP scores of neighbors\n",
        "2) Calculate the l1-distance of the pari-wise neighbors\n",
        "3) Do Top-P Sampling using distances\n",
        "3-1) Sort l1-distance while keeping the track of indices ---> concatenated_features_matrix : center_indices, neighbor_indices\n",
        "4) adj matrix modified in a such way that only top-neighbors remained\n",
        "5) find the not top-p neighbors and make the entry in adj matrix zero\n",
        "\n",
        "\n",
        "6) Algorithm :\n",
        "6-1) iterate over unique center nodes\n",
        "6-2) create a mask that identify which indices are for each unique node\n",
        "6-3) applying mask to sorted neighbor indices and l1-distances\n",
        "6-4) choose the top-p neighbors according to the p provided for each node\n",
        "6-5) use these selected neighbors to modify the adj matrix to refelect the sampled the neighbors\n",
        "\n",
        "\n",
        "Top-P sampeling onlu differs between node relationship types.\n",
        "\n",
        "Recom : partition 5 random groups\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jtcjm26xYtOj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "e9739b55-c08e-4340-98f8-f8717b3e39b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n0) Construct concatenate features matrix ---> concatenated_features_matrix\\n1) Calculate MLP scores of neighbors\\n2) Calculate the l1-distance of the pari-wise neighbors\\n3) Do Top-P Sampling using distances\\n3-1) Sort l1-distance while keeping the track of indices ---> concatenated_features_matrix : center_indices, neighbor_indices\\n4) adj matrix modified in a such way that only top-neighbors remained\\n5) find the not top-p neighbors and make the entry in adj matrix zero\\n\\n\\n6) Algorithm :\\n6-1) iterate over unique center nodes\\n6-2) create a mask that identify which indices are for each unique node\\n6-3) applying mask to sorted neighbor indices and l1-distances\\n6-4) choose the top-p neighbors according to the p provided for each node\\n6-5) use these selected neighbors to modify the adj matrix to refelect the sampled the neighbors\\n\\n\\nTop-P sampeling onlu differs between node relationship types.\\n\\nRecom : partition 5 random groups\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H9o22mWj3_k"
      },
      "outputs": [],
      "source": [
        "def concatenate_features_optimized(feature_matrix, adjacency_matrix):\n",
        "    num_nodes, num_features = feature_matrix.shape\n",
        "\n",
        "    # Create indices for center nodes and their neighbors based on the adjacency matrix\n",
        "    center_indices, neighbor_indices = torch.nonzero(adjacency_matrix, as_tuple=True)\n",
        "    # print(center_indices, '\\n',\n",
        "    #       neighbor_indices)\n",
        "\n",
        "    # Extract features for center nodes and their neighbors\n",
        "    center_features = feature_matrix[center_indices]\n",
        "    neighbor_features = feature_matrix[neighbor_indices]\n",
        "\n",
        "\n",
        "    # Concatenate the features along dimension 1\n",
        "    concatenated_features = torch.cat((center_features.unsqueeze(1), neighbor_features.unsqueeze(1)), dim=1)\n",
        "    # print(concatenated_features)\n",
        "\n",
        "    # Reshape to the desired output format (num_pairs, num_features * 2)\n",
        "    #concatenated_features = concatenated_features.view(-1, num_features * 2)\n",
        "    #print(concatenated_features)\n",
        "\n",
        "\n",
        "    return concatenated_features,center_indices, neighbor_indices\n",
        "\n",
        "# Example usage\n",
        "FF = torch.tensor([[1, 2], [3, 4], [5, 6],[8,9],[10,11]], dtype=torch.float32)  # Feature matrix\n",
        "A = torch.tensor([[0, 1, 0,0,1], [1, 0, 1,0,0], [0, 1, 0,1,1],[0,0,1,0,0],[1,0,1,0,0]], dtype=torch.float32)  # Adjacency matrix\n",
        "\n",
        "concatenated_features_matrix,center_indices, neighbor_indices = concatenate_features_optimized(FF, A)\n",
        "#df_concatenated_features = pd.DataFrame(concatenated_features_matrix.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2,2),\n",
        "    nn.Tanh()\n",
        "    )\n",
        "\n",
        "def sort_l1_distance ( model , concatenated_features_matrix,center_indices, neighbor_indices ) :\n",
        "\n",
        "  concatenated_scores = model(concatenated_features_matrix)\n",
        "  l1_distances = torch.sum(torch.abs(concatenated_scores[:, 0, :] - concatenated_scores[:, 1, :]), dim=1)\n",
        "  #\n",
        "  # Step 2: Sort the L1-distances while keeping track of the indices\n",
        "  sorted_l1_distances, sorted_indices = torch.sort(l1_distances)\n",
        "  # Step 3: Use the sorted indices to sort the center and neighbor nodes\n",
        "  sorted_center_nodes = center_indices[sorted_indices]\n",
        "  sorted_neighbor_nodes = neighbor_indices[sorted_indices]\n",
        "\n",
        "\n",
        "  return sorted_center_nodes, sorted_l1_distances, sorted_indices , sorted_neighbor_nodes\n",
        "\n",
        "sorted_center_nodes, sorted_l1_distances, sorted_indices , sorted_neighbor_nodes = sort_l1_distance (\n",
        "                                                                                  model ,\n",
        "                                                                                  concatenated_features_matrix,\n",
        "                                                                                  center_indices,\n",
        "                                                                                  neighbor_indices )\n"
      ],
      "metadata": {
        "id": "20yLvN--X93d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_p_sampling(top_ps,adj_mat,sorted_center_nodes,sorted_l1_distances,\n",
        "                   sorted_indices,center_indices,neighbor_indices):\n",
        "  sampled_l1_distance_list = []\n",
        "  sampled_center_node_list = []\n",
        "  sampled_neigh_node_list = []\n",
        "  for center_node,center_neighs in enumerate(adj_mat) :\n",
        "    mask = sorted_center_nodes == center_node\n",
        "    center_filtered = center_indices[sorted_indices]\n",
        "    neigh_filtered = neighbor_indices[sorted_indices]\n",
        "    top_p = top_ps[center_node]\n",
        "    if top_p * len(neigh_filtered[mask]) > 1 :\n",
        "      slice_end = int(np.floor(top_p * len(neigh_filtered[mask])))\n",
        "    else :\n",
        "      slice_end = None\n",
        "\n",
        "    sampled_l1_distance = sorted_l1_distances[mask][:slice_end]\n",
        "    sampled_center_node = center_filtered[mask][:slice_end]\n",
        "    sampled_neigh_node = neigh_filtered[mask][:slice_end]\n",
        "\n",
        "    sampled_l1_distance_list.append(sampled_l1_distance)\n",
        "    sampled_center_node_list.append(sampled_center_node)\n",
        "    sampled_neigh_node_list.append(sampled_neigh_node)\n",
        "\n",
        "  return sampled_l1_distance_list, sampled_center_node_list, sampled_neigh_node_list\n",
        "\n",
        "# sampled_l1_distance, sampled_center_node, sampled_neigh_node = top_p_sampling(top_ps,\n",
        "#                                                        A,sorted_center_nodes,sorted_l1_distances,\n",
        "#                                                        sorted_indices,center_indices,neighbor_indices)"
      ],
      "metadata": {
        "id": "SzYeenfowVt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adj_mat_neighbor_selection (num_nodes , sampled_center_node , sampled_neigh_node ) :\n",
        "  # Sample parallel lists of indices\n",
        "  i_indices = torch.cat(sampled_center_node).tolist()\n",
        "  j_indices = torch.cat(sampled_neigh_node).tolist()\n",
        "\n",
        "  data = np.ones(len(i_indices))  # All non-zero values are 1\n",
        "\n",
        "# Assuming the size of the matrix is known or can be derived\n",
        "  print(num_nodes)\n",
        "  num_rows = num_nodes\n",
        "  num_columns = num_nodes\n",
        "\n",
        "  # Create the sparse matrix\n",
        "  sparse_matrix = coo_matrix((data, (i_indices, j_indices)), shape=(num_rows, num_columns))\n",
        "\n",
        "  # Convert the sparse matrix to a dense matrix\n",
        "  dense_matrix = sparse_matrix.toarray()\n",
        "\n",
        "  return dense_matrix , sparse_matrix\n",
        "\n",
        "# dense_matrix , sparse_matrix = adj_mat_neighbor_selection (5 , sampled_center_node , sampled_neigh_node)"
      ],
      "metadata": {
        "id": "Y12W3oNoHR22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neighbor_selection (feature_matrix, adjacency_matrix , model) :\n",
        "  num_nodes = len(adjacency_matrix)\n",
        "  top_ps =[ 0.5 for i in range(num_nodes)]\n",
        "  concatenated_features_matrix, center_indices, neighbor_indices = concatenate_features_optimized(feature_matrix, adjacency_matrix)\n",
        "  sorted_center_nodes, sorted_l1_distances, sorted_indices , sorted_neighbor_nodes = sort_l1_distance (\n",
        "                                                                                  model ,\n",
        "                                                                                  concatenated_features_matrix,\n",
        "                                                                                  center_indices,\n",
        "                                                                                  neighbor_indices )\n",
        "  sampled_l1_distance, sampled_center_node, sampled_neigh_node = top_p_sampling(top_ps,\n",
        "                                                       A,sorted_center_nodes,sorted_l1_distances,\n",
        "                                                       sorted_indices,center_indices,neighbor_indices)\n",
        "  dense_matrix , sparse_matrix = adj_mat_neighbor_selection (num_nodes , sampled_center_node , sampled_neigh_node)\n",
        "\n",
        "  return dense_matrix , sparse_matrix\n",
        "\n",
        "# dense_matrix , sparse_matrix = neighbor_selection(feature_matrix, adjacency_matrix , model)"
      ],
      "metadata": {
        "id": "y3hhhQVVc628"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix , sparse_matrix = neighbor_selection(FF, A , model)\n",
        "dense_matrix"
      ],
      "metadata": {
        "id": "3N_S8JtoHvuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2c0de3-50b5-494b-b94f-5416212bef62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 1.],\n",
              "       [1., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_to_dic_adjacency(edge_index):\n",
        "  dic = {}\n",
        "  for i in edge_index[0] :\n",
        "    dic[int(i)] = list()\n",
        "\n",
        "  for key,value in zip(edge_index[0],edge_index[1]) :\n",
        "    dic[int(key)].append(int(value))\n",
        "  return dic\n",
        "\n",
        "adjacency_list_dict = edge_to_dic_adjacency(edge_index)\n",
        "adjacency_list_dict_train = edge_to_dic_adjacency(edge_index_train)"
      ],
      "metadata": {
        "id": "dEwQNbe3dWdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "4VNijf5b5qq5",
        "outputId": "60f373b8-ac82-464a-cfa3-9bea62b7f4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-60079704bed2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11701\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11701\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0medge_to_adj_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5YFmVk9F4cW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dic_to_adjmatrix(adjacency_list_dict,num_nodes):\n",
        "  # adjacency_list_dict\n",
        "  adj_matrix = np.zeros((num_nodes,num_nodes))\n",
        "  for node in adjacency_list_dict.keys() :\n",
        "    for neighbor in adjacency_list_dict[node] :\n",
        "      adj_matrix[neighbor][node] = 1\n",
        "  return adj_matrix\n",
        "\n",
        "adj_matrix = torch.tensor(dic_to_adjmatrix(adjacency_list_dict,11701),dtype = torch.float32)\n",
        "adj_matrix_train = torch.tensor(dic_to_adjmatrix(adjacency_list_dict_train,11701),dtype = torch.float32)"
      ],
      "metadata": {
        "id": "8jtB4sIXeO2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(300,2),\n",
        "    nn.Tanh()\n",
        "    )\n",
        "dense_matrix , sparse_matrix = neighbor_selection(data.x, adj_matrix , model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDTeFqs2df6l",
        "outputId": "4924f411-2d06-4836-d74c-0954e9849ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# test\n",
        "# a = torch.tensor(dense_matrix) - adj_matrix\n",
        "# b = a[a<0]\n",
        "# b\n",
        "# torch.dot                            # [D], [D] -> []\n",
        "# batched_dot = torch.vmap(torch.dot)  # [N, D], [N, D] -> [N]\n",
        "# x, y = torch.randn(100000, 5), torch.randn(100000, 5)\n",
        "# z = batched_dot(x, y)\n",
        "# z"
      ],
      "metadata": {
        "id": "MVwI6xNydWgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6r02rjsf3mTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def norm_mat_gen(adj_mat):\n",
        "  degrees = torch.sum(adj_mat,axis = 1)\n",
        "  inv_degrees = torch.where(degrees > 0, 1.0 / degrees, torch.zeros_like(degrees))\n",
        "  norm_mat = torch.diag(inv_degrees)\n",
        "  return norm_mat\n",
        "\n",
        "# matrix_test = torch.tensor([[0,0,1,1],[0,0,0,1],[1,0,0,1],[1,1,1,0]],dtype = torch.float32)\n",
        "norm_mat = norm_mat_gen(adj_matrix)\n",
        "norm_adj_mat = torch.spmm(norm_mat,adj_matrix)"
      ],
      "metadata": {
        "id": "mgSOYXaMdWiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m5YknS7m3VT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomGNNLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(CustomGNNLayer, self).__init__()\n",
        "        # self.linear = nn.Linear(in_channels, out_channels)\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(in_features,out_features))\n",
        "        self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
        "\n",
        "        init.xavier_uniform_(self.weight)\n",
        "        init.zeros_(self.bias)\n",
        "\n",
        "\n",
        "    def forward(self, x, norm_adj_mat):\n",
        "        # TODO : add neighbor selection\n",
        "        x = torch.spmm(norm_adj_mat,x)\n",
        "        x = torch.mm(x,self.weight)\n",
        "        x = x + self.bias\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "aCs9g6grdWk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeighborSelectionLayer(nn.Module):\n",
        "  def __init__ (self):\n",
        "    super(NeighborSelectionLayer, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "                nn.Linear(300,2),\n",
        "                nn.Tanh()\n",
        "                )\n",
        "    num_nodes = 11701\n",
        "    self.top_ps = [ 0.9 for i in range(num_nodes)]\n",
        "  def forward(self, x, norm_adj_mat):\n",
        "    new_adj_mat = self.neighbor_selection(x , norm_adj_mat)\n",
        "\n",
        "    return new_adj_mat\n",
        "\n",
        "  def concatenate_features_optimized(self ,feature_matrix, adjacency_matrix):\n",
        "    num_nodes, num_features = feature_matrix.shape\n",
        "\n",
        "    center_indices, neighbor_indices = torch.nonzero(adjacency_matrix, as_tuple=True)\n",
        "\n",
        "    center_features = feature_matrix[center_indices]\n",
        "    neighbor_features = feature_matrix[neighbor_indices]\n",
        "\n",
        "    concatenated_features = torch.cat((center_features.unsqueeze(1), neighbor_features.unsqueeze(1)), dim=1)\n",
        "\n",
        "    return concatenated_features,center_indices, neighbor_indices\n",
        "\n",
        "  def sort_l1_distance (self , concatenated_features_matrix,center_indices, neighbor_indices ) :\n",
        "\n",
        "    concatenated_scores = self.model(concatenated_features_matrix)\n",
        "    l1_distances = torch.sum(torch.abs(concatenated_scores[:, 0, :] - concatenated_scores[:, 1, :]), dim=1)\n",
        "\n",
        "    sorted_l1_distances, sorted_indices = torch.sort(l1_distances)\n",
        "\n",
        "    sorted_center_nodes = center_indices[sorted_indices]\n",
        "    sorted_neighbor_nodes = neighbor_indices[sorted_indices]\n",
        "\n",
        "\n",
        "    return sorted_center_nodes, sorted_l1_distances, sorted_indices , sorted_neighbor_nodes\n",
        "\n",
        "  def top_p_sampling(self ,adj_mat,sorted_center_nodes,sorted_l1_distances,\n",
        "                   sorted_indices,center_indices,neighbor_indices):\n",
        "    sampled_l1_distance_list = []\n",
        "    sampled_center_node_list = []\n",
        "    sampled_neigh_node_list = []\n",
        "    for center_node,center_neighs in enumerate(adj_mat) :\n",
        "      mask = sorted_center_nodes == center_node\n",
        "      center_filtered = center_indices[sorted_indices]\n",
        "      neigh_filtered = neighbor_indices[sorted_indices]\n",
        "      top_p = self.top_ps[center_node]\n",
        "      if top_p * len(neigh_filtered[mask]) > 1 :\n",
        "        slice_end = int(np.floor(top_p * len(neigh_filtered[mask])))\n",
        "      else :\n",
        "        slice_end = None\n",
        "\n",
        "      sampled_l1_distance = sorted_l1_distances[mask][:slice_end]\n",
        "      sampled_center_node = center_filtered[mask][:slice_end]\n",
        "      sampled_neigh_node = neigh_filtered[mask][:slice_end]\n",
        "\n",
        "      sampled_l1_distance_list.append(sampled_l1_distance)\n",
        "      sampled_center_node_list.append(sampled_center_node)\n",
        "      sampled_neigh_node_list.append(sampled_neigh_node)\n",
        "\n",
        "    return sampled_l1_distance_list, sampled_center_node_list, sampled_neigh_node_list\n",
        "\n",
        "  def adj_mat_neighbor_selection (self ,num_nodes , sampled_center_node , sampled_neigh_node ) :\n",
        "\n",
        "    i_indices = torch.cat(sampled_center_node).tolist()\n",
        "    j_indices = torch.cat(sampled_neigh_node).tolist()\n",
        "\n",
        "    data = np.ones(len(i_indices))\n",
        "\n",
        "    num_rows = num_nodes\n",
        "    num_columns = num_nodes\n",
        "\n",
        "    sparse_matrix = coo_matrix((data, (i_indices, j_indices)), shape=(num_rows, num_columns))\n",
        "\n",
        "    dense_matrix = sparse_matrix.toarray()\n",
        "\n",
        "    return dense_matrix , sparse_matrix\n",
        "\n",
        "  def norm_mat_gen(self , adj_mat):\n",
        "    degrees = torch.sum(adj_mat,axis = 1)\n",
        "    inv_degrees = torch.where(degrees > 0, 1.0 / degrees, torch.zeros_like(degrees))\n",
        "    norm_mat = torch.diag(inv_degrees)\n",
        "    return norm_mat\n",
        "\n",
        "\n",
        "  def neighbor_selection (self ,feature_matrix, adjacency_matrix) :\n",
        "    num_nodes = len(adjacency_matrix)\n",
        "    concatenated_features_matrix, center_indices, neighbor_indices = self.concatenate_features_optimized(feature_matrix, adjacency_matrix)\n",
        "    sorted_center_nodes, sorted_l1_distances, sorted_indices , sorted_neighbor_nodes = self.sort_l1_distance (\n",
        "                                                                                    concatenated_features_matrix,\n",
        "                                                                                    center_indices,\n",
        "                                                                                    neighbor_indices )\n",
        "    sampled_l1_distance, sampled_center_node, sampled_neigh_node = self.top_p_sampling(\n",
        "                                                        A,sorted_center_nodes,sorted_l1_distances,\n",
        "                                                        sorted_indices,center_indices,neighbor_indices)\n",
        "    dense_matrix , sparse_matrix = self.adj_mat_neighbor_selection (num_nodes , sampled_center_node , sampled_neigh_node)\n",
        "\n",
        "    norm_adj_mat = self.norm_mat_gen(torch.tensor(dense_matrix, dtype = torch.float32))\n",
        "    return norm_adj_mat\n"
      ],
      "metadata": {
        "id": "YsOKVij8ifSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : find out if the parameters of MLP layer calculating l1-distance are being updated.\n"
      ],
      "metadata": {
        "id": "lOFmvvItlXes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1p8B-7Hxmd_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jxWRGx4smeCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0YWPmVJ5lXy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = CustomGNNLayer(in_channels, hidden_channels)\n",
        "        self.conv2 = CustomGNNLayer(hidden_channels, out_channels)\n",
        "        self.neighb_select = NeighborSelectionLayer()\n",
        "\n",
        "    def forward(self, x, norm_adj_mat):\n",
        "        norm_adj_mat = self.neighb_select(x , norm_adj_mat)\n",
        "        x = self.conv1(x, norm_adj_mat)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, norm_adj_mat)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pH0VNLEEdZgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, optimizer, and loss function\n",
        "model = GCN(300, 16, 10)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-12)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# criterion = nn.MSELoss()\n",
        "train_negtest = torch.logical_not(data.test_mask)\n",
        "num_epoch = 150\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  out = model(data.x, norm_adj_mat)\n",
        "  # loss = criterion(out, one_hot_labels)\n",
        "  #train loss\n",
        "  loss = criterion(out[train_negtest], one_hot_labels[train_negtest])\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch {epoch}, Loss: {loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "UV7NqnZ6dZjj",
        "outputId": "d6a5761d-cc6b-44a8-abf7-b7f041fb870e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.3026\n",
            "Epoch 10, Loss: 2.2472\n",
            "Epoch 20, Loss: 2.2032\n",
            "Epoch 30, Loss: 2.1696\n",
            "Epoch 40, Loss: 2.1446\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-678592af359e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_adj_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;31m# loss = criterion(out, one_hot_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m#train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-41cce8922c7f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, norm_adj_mat)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_adj_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnorm_adj_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighb_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnorm_adj_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_adj_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-f62cd9711611>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, norm_adj_mat)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;36m0.9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_adj_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnew_adj_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbor_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnorm_adj_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_adj_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-f62cd9711611>\u001b[0m in \u001b[0;36mneighbor_selection\u001b[0;34m(self, feature_matrix, adjacency_matrix)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mdense_matrix\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msparse_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_mat_neighbor_selection\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msampled_center_node\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msampled_neigh_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mnorm_adj_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_mat_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnorm_adj_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BnDDv8pqnrGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8oSEHE1nrJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}